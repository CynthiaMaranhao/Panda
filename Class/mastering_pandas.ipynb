{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data transformation from previous notebooks\n",
    "nyc = pd.read_csv('../data/central-park-raw.csv', parse_dates=[0])\n",
    "# put it all in a function\n",
    "def fix_col(colname):\n",
    "    return colname.strip().replace(' ', '_')\n",
    "\n",
    "def tweak_nyc(df_):\n",
    "    return (df_\n",
    "            .rename(columns=fix_col)\n",
    "            .assign(PrecipitationIn = pd.to_numeric(df_.PrecipitationIn.replace(\"T\", '0.001')),\n",
    "                    Events=lambda df2: df2['Events'].fillna(''),\n",
    "                    PrecipitationCm=lambda df2:df2.PrecipitationIn * 2.54)\n",
    "           )\n",
    "\n",
    "nyc = tweak_nyc(nyc)\n",
    "nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Stats\n",
    "\n",
    "A nice feature of pandas is that you can quickly inspect data and get summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe method gives us basic stats. The result is a Data Frame\n",
    "nyc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Remember transpose\n",
    "nyc.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view non-numeric data pass include='all'\n",
    "nyc.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various aggregation methods (max, mean, median, min, mad, skew, kurtosis, autocorr,\n",
    "#   nunique, sem, std, var)\n",
    "# and properties (hasnans, is_monotonic, is_unique)\n",
    "nyc.Max_Humidity.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_Humidity.quantile(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_Humidity.quantile([.2,.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_Humidity.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Mean_Humidity.corr(nyc.Mean_TemperatureF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Lab Data\n",
    "https://archive.ics.uci.edu/ml/datasets/El+Nino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nino_col(name):\n",
    "    return name.rstrip('.').replace('.', '_').replace(' ', '_')\n",
    "def tweak_nino(df_):\n",
    "    return (df_\n",
    "           .rename(columns=fix_nino_col)\n",
    "           .assign(air_temp_F=lambda df2:df2.air_temp*9/5+32,\n",
    "                   zon_winds_mph=lambda df2:df2.zon_winds / 2.237,\n",
    "                   mer_winds_mph=lambda df2:df2.mer_winds / 2.237,\n",
    "                   date=pd.to_datetime(df_.date, format='%y%m%d')\n",
    "                  )\n",
    "            .drop(columns='obs')\n",
    "           )\n",
    "\n",
    "names = '''obs\n",
    "year\n",
    "month\n",
    "day\n",
    "date\n",
    "latitude\n",
    "longitude\n",
    "zon.winds\n",
    "mer.winds\n",
    "humidity\n",
    "air temp.\n",
    "s.s.temp.'''.split('\\n')\n",
    "\n",
    "nino = pd.read_csv('../data/tao-all2.dat.gz', sep=' ', names=names, na_values='.',\n",
    "                  parse_dates=[[1,2,3]])\n",
    "\n",
    "nino = tweak_nino(nino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Stats Exercise\n",
    "With the nino dataset:\n",
    "\n",
    "* *Describe* the data\n",
    "* Choose a column\n",
    "  * Print out the max, min, and mean\n",
    "* Correlate (``corr``) the temperature column with the date column (might need to use ``.astype('int64')`` method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "\n",
    "Pandas has built-in integration with Matplotlib. Other libraries such as Seaborn also support plotting DataFrames and Series. This is not an in depth intro to Matplotlib, but their website and gallery are great for finding more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms are a quick way to visualize the distribution\n",
    "nyc.Mean_Humidity.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the output. Get rid of it by assigning to an \"ignored\" variable\n",
    "_ = nyc.Mean_Humidity.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in figsize=(width,height) to boost size\n",
    "nyc.Mean_Humidity.hist(figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use the .plot method we can add title and other attributes\n",
    "nyc.Mean_Humidity.plot.hist(title='Avg Humidity', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.plot(x='EST', y='Mean_Humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.plot(x='EST', y='Mean_Humidity', figsize=(12, 6) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can resample columns, since our index is a date we can use *Offset Aliases*\n",
    "# see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
    "nyc.set_index('EST').Mean_Humidity.resample('M').mean().plot(figsize=(10, 6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can resample columns, since our index is a date we can use *Offset Aliases*\n",
    "# see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
    "(nyc\n",
    " .set_index('EST')\n",
    " .Mean_Humidity\n",
    " .resample('M')\n",
    " .mean()\n",
    " .plot(figsize=(10, 6)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can resample columns, since our index is a date we can use *Offset Aliases*\n",
    "# see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n",
    "(nyc\n",
    " .set_index('EST')\n",
    " .Mean_Humidity\n",
    " .resample('2W')\n",
    " .mean()\n",
    " .plot(figsize=(10, 6)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the things (may be useful or just art)\n",
    "nyc.set_index('EST').plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.plot.scatter(x='Max_TemperatureF', y='Max_Humidity', alpha=.5, \n",
    "        figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_TemperatureF.corr(nyc.Max_Humidity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Exercise\n",
    "With the nino dataset:\n",
    "* Plot a histogram of air temp\n",
    "* Plot a scatter plot of latitude and longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# When we apply a conditional operator to a series we get back a series of True/False values\n",
    "# We call this a \"mask\", which we can use to filter (similar to Photoshop)\n",
    "# all EST in 2000's\n",
    "m2000 = nyc.EST.dt.year >= 2000\n",
    "\n",
    "# below 2010\n",
    "lt2010 = nyc.EST.dt.year < 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"and\" operation looks at whether the operands are truthy or falsey\n",
    "# This is a case where normal Python syntax doesn't work\n",
    "nyc[m2000 and lt2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# & does bitwise comparisons - which is what we want\n",
    "nyc[m2000 & lt2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beware if you embed the operations, the bitwise operator binds more tightly to the integers\n",
    "nyc[nyc.EST.dt.year >= 2000 & nyc.EST.dt.year < 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beware if you embed the operations, the bitwise operator binds more tightly to the integers\n",
    "nyc[(nyc.EST.dt.year >= 2000) & (nyc.EST.dt.year < 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dec = nyc.EST.dt.month == 12\n",
    "nyc[m_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use loc to filter out based on index value, also takes a boolean index\n",
    "# In fact, you should use .loc instead as a matter of habit (you won't see warnings)\n",
    "nyc.loc[m_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use loc to filter out based on index value, also takes a boolean index\n",
    "# 2nd option in index op is column names (: to include everything)\n",
    "nyc.loc[m_dec, [x for x in nyc.columns if 'Max' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc note:\n",
    "# can use set_index and sort_index to do quick lookups (if you sort you get quick lookups)\n",
    "nyc.set_index('Events').sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nyc\n",
    " .set_index('Events')\n",
    " .sort_index()\n",
    " .loc['Fog']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Can use iloc to filter out based on index location (or position)\n",
    "# 2nd option in index op is column indices\n",
    "nyc.iloc[5:10, [2, 5, -2]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use iloc to filter out based on index location\n",
    "# 2nd option in index op is column indices\n",
    "nyc.iloc[:, [2, 5, -2]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Exercise\n",
    "Using the nino dataframe:\n",
    "* Create a mask, ``m80``, that all years >= 1980 and < 1990\n",
    "* Create a mask, ``m90``, that all years >= 1990 and < 2000\n",
    "* Create a mask, ``lon120``, that has all longitudes > 120\n",
    "* Create a mask, ``lat0``, that has latitudes > -2 and < 2\n",
    "* Create a dataframe, ``df80``, that has only those values in ``m80`` and ``lon120`` and ``lat0``\n",
    "* Create a dataframe, ``df90``, that has only those values in ``m90`` and ``lon120`` and ``lat0``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows that have null data\n",
    "# fish create a mask\n",
    "nyc.isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missing trick\n",
    "nyc.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent missing trick\n",
    "nyc.isna().mean().mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc[nyc.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = nyc.isna() \n",
    "nyc[missing_df.Max_TemperatureF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.loc[2218:2221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.Max_TemperatureF.fillna(nyc.Max_TemperatureF.mean()).loc[2218:2221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .interpolate method will do linear interpolation by default\n",
    "nyc.Max_TemperatureF.interpolate().loc[2218:2221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill\n",
    "nyc.Max_TemperatureF.ffill().loc[2218:2221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill\n",
    "nyc.Max_TemperatureF.bfill().loc[2218:2221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tack on a plot to visualize\n",
    "nyc.Max_TemperatureF.bfill().loc[2218:2221].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with missing data\n",
    "nyc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN Exercise\n",
    "With the nino dataset:\n",
    "* Find the rows that have null data\n",
    "* Find the columns that have null data\n",
    "* It looks like the ``zon_winds`` has some missing values, use summary stats or plotting to determine how to fill in those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "Pandas allows us to perform aggregates calculations over grouped portions of ``Series`` or ``DataFrames``. The ``.groupby`` method is the low level workhorse that enables this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can group by a column, but if it has unique values it isn't useful\n",
    "nyc.groupby('EST').mean()['CloudCover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can group by a column, but if it has unique values it isn't useful\n",
    "(nyc\n",
    " .groupby('EST')\n",
    " .mean()\n",
    " ['CloudCover']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the average cloud cover each month\n",
    "(nyc\n",
    " .groupby(nyc.EST.dt.month)\n",
    " .mean()\n",
    " ['CloudCover']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous aggregated over every month, \n",
    "# what if we want to group by year and month?\n",
    "(nyc\n",
    " .groupby([nyc.EST.dt.year, nyc.EST.dt.month])\n",
    " .mean()\n",
    " ['CloudCover']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous aggregated over every month, \n",
    "# what if we want to group by year and month?\n",
    "(nyc\n",
    " .groupby([nyc.EST.dt.year, nyc.EST.dt.month])\n",
    " .mean()\n",
    " ['CloudCover']\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fix date/index can use grouper\n",
    "(nyc\n",
    " .groupby(pd.Grouper(key='EST', freq='M'))\n",
    " .mean()\n",
    " ['CloudCover']\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the .agg method we can apply many functions\n",
    "(nyc\n",
    " .groupby(pd.Grouper(key='EST', freq='M'))\n",
    " .agg(['mean', 'max', 'count'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out a column\n",
    "(nyc\n",
    " .groupby(pd.Grouper(key='EST', freq='M'))\n",
    " .agg(['mean', 'max', 'count'])\n",
    " .Mean_TemperatureF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then Plot\n",
    "(nyc\n",
    " .groupby(pd.Grouper(key='EST', freq='M'))\n",
    " .agg(['mean', 'max', 'count'])\n",
    " .Mean_TemperatureF\n",
    " .plot()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Exercise\n",
    "With the nino dataset:\n",
    "* Find the mean temperature for each year\n",
    "* Find the count of entries for each year\n",
    "* Find the max temperature for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.pivot_table(index=[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month],\n",
    "                aggfunc=[np.max, np.count_nonzero],\n",
    "               values=['Max_Humidity', 'Max_Dew_PointF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.pivot_table(index=[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month],\n",
    "                aggfunc=[np.max, np.count_nonzero],\n",
    "               values=['Max_Humidity', 'Max_Dew_PointF']).plot(figsize=(14,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix x-axis with grouper\n",
    "nyc.pivot_table(index=pd.Grouper(key='EST', freq='m'), #[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month],\n",
    "                aggfunc=[np.max, np.count_nonzero],\n",
    "               values=['Max_Humidity', 'Max_Dew_PointF']).plot(figsize=(14,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to multi-index....\n",
    "# We can \"unstack\" to pull a left index into a column (0 is the left most index)\n",
    "(nyc\n",
    " .pivot_table(index=[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month], \n",
    "              aggfunc=[np.max, np.count_nonzero],\n",
    "              values=['Max_Humidity', 'Max_Dew_PointF'])\n",
    " .unstack(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can \"unstack\" to pull a left index into a column (1 is the 2nd index)\n",
    "(nyc\n",
    " .pivot_table(index=[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month], \n",
    "              aggfunc=[np.max, np.count_nonzero],\n",
    "              values=['Max_Humidity', 'Max_Dew_PointF'])\n",
    " .unstack(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just use one value and one aggregation\n",
    "(nyc\n",
    " .pivot_table(index=[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month], \n",
    "              aggfunc=np.max,\n",
    "              values='Mean_TemperatureF')\n",
    " .unstack(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just use one value and one aggregation\n",
    "(nyc\n",
    " .pivot_table(index=[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month], \n",
    "              aggfunc=np.max,\n",
    "              values='Mean_TemperatureF')\n",
    " .unstack(1)\n",
    " .plot(cmap='jet', figsize=(10,6))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just use one value and one aggregation\n",
    "(nyc\n",
    " .pivot_table(index=[nyc.EST.dt.year.rename('year'), nyc.EST.dt.month], \n",
    "              aggfunc=np.max,\n",
    "              values='Mean_TemperatureF')\n",
    " .unstack(0)\n",
    " .plot(cmap='viridis', figsize=(10,6))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting Exercise\n",
    "With the nino dataset:\n",
    "* Pivot the nino data using the ``.pivot_table`` method. Group by year and month, the ``air_temp`` column. Reduce using the ``max``, ``min``, and ``np.mean`` functions. (You will either need to create a month column or use ``year_month_day.dt.month``)\n",
    "* Plot a line plot of the previous pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting Bonus Exercise\n",
    "\n",
    "* Using ``.groupby`` we can sometimes perform the same operation as pivot tables. Pivot the nino data using the ``.groupby`` method. Group by year and month, the ``air_temp_`` column. Reduce using the ``max``, ``min``, and ``np.mean`` functions using ``.groupby``. (Hint: Use the ``.agg`` method on the result of the group by)\n",
    "* Use ``.unstack`` to see the mean ``air_temp_`` by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
